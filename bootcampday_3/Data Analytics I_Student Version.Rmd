---
title: 'Data Analytics I'
author: "QBS Bootcamp 2025"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Lesson Objectives

## At the end of this lecture you should be able to:
1. Calculate appropriate summary statistics for a data frame
2. Build simple loops
3. Build simple functions
4. Leverage loops and functions to analyze data
5. Create table one


# Calculate Appropriate Summary Statistics

First, lets generate some random data.

``` {r message = F, warning = F}
library(tidyverse)
set.seed(3927)

randomData <- data.frame(Cont1 = rnorm(n = 1000,mean = 50,sd = 10), # continuous variable
                         Cont2 = rnorm(n = 1000, mean = 23,sd = 2), # continuous variable
                         Cont3 = rexp(n = 1000,rate = 0.25), # continuous variable
                         Cat1 = factor(rbinom(n = 1000,size = 1,prob = 0.50), # categorical variable
                                       labels = c(F,T)), 
                         Cat2 = factor(rbinom(n = 1000,size = 1,prob = 0.25), # categorical variable
                                       labels = c(F,T)),
                         Cat3 = factor(rbinom(n = 1000,size = 2,prob = 0.40), # categorical variable
                                       labels = c('A','B','C')))

head(randomData)
```

## Continuous Variables

For normally distributed continuous variables, we report mean and standard deviation.

``` {r}
# check distribution with histogram
ggplot(data = randomData,aes(x = Cont1)) +
  geom_histogram(binwidth = 5) + 
  labs(x = 'Continuous Variable 1',y = 'Frequency') +
  theme_classic()
```

We can extract all the individual components of mean and standard deviation using the following functions.

``` {r}
# Mean
mean(randomData$Cont1)

# Standard deviation
sd(randomData$Cont1)
```

We can then combine these values to make them nicely formatted.

``` {r}
# combine meand and SD
print(paste0('Mean (sd): ',round(mean(randomData$Cont1),digits = 2),' (',
             round(sd(randomData$Cont1),digits = 2),')'))
```

For non-normally distributed continuous variables, we report median and interquartile range (IQR). 

``` {r}
# check distribution with histogram
ggplot(data = randomData, aes(x = Cont3)) +
  geom_histogram(binwidth = 2) +
  labs(x = 'Continuous Variable 3',
       y = "Frequency") + theme_classic()
```

We can extract all the individual components of median and IQR using the following functions.

``` {r}
# Median
median(randomData$Cont3)

# Quartile values
quantile(randomData$Cont3)

# IQR (Q3 - Q1)
IQR(randomData$Cont3)
```

We can string these values together as follows to print out a clean and easy to read summary.

``` {r}
# combine median and IQR
print(paste0('Median [IQR]: ',round(median(randomData$Cont3),digits = 2),' [',
             round(quantile(randomData$Cont3,1/4),digits = 2),', ',
             round(quantile(randomData$Cont3,3/4),digits = 2),']'))
```

## Categorical Variables

For categorical covariates, we typically report the count (n) and percentage of each level of that variable.

``` {r}
data.frame('n' = c(table(randomData$Cont1)),
           'perc' = c(round(table(randomData$Cat1)/1000*100, digits = 2)))
```

# Loops

## Refresh: What Is A Loop?
As you begin your first foray into R programming, you may find that you need to conduct repetitive tasks such as printing out the third item of ten different lists. You could begin the tedious exercise of picking out the third item in each of the ten lists by hand, but let's be honest, you have better things to. There true crime documentaries to watch on Netflix. Your favorite author just came out with a new book. You need to train your dog or cat to make an adorable face on command. Good news, R can free up this time with loops!

In a loop you can define a set of instructions that R will execute a certain number of times or over a set of variables. There are three types of loops in R: the for loop, the while loop, and the repeat loop. The for loop is the most commonly used and dynamic loop. Let's begin there!

## For Loops

The simplest implementation of a for loop is to conduct a task x number of times.

In the following code, we are printing the numbers 1 to 10:

```{r}
for (i in 1:10){
  print(i)
}
```

This code will repeat ten times, as indicated by the `1:10`. The `i` stands for index. Over each iteration of the loop `i` will change. In the first loop `i` is 1. In the second `i` is 2 and so on. We are not required to start the loop at 1. Change `1:10` to `2:10` and see what happens.

We have the power to conduct more complex tasks within for loop. Let's say we need to add 2 to each integer between 1 and 3.

```{r}
for (i in 1:3){
  print(i+2)
}
```

We added 2 to all of the numbers between 1 and 3 and printed them. Simple enough, but what if we need to store variables within a for loop? No problem! In the following code we save the result of `i + 2` to the variable y.

```{r}
for (i in 1:3){
  y = i + 2
  print(y)
}
```

You may be wondering why we would want to save our result to a variable and then print it. Seems redundant, but we may need to conduct further tasks on our y variable. Let's say we want to divide y by 3 and print that result. We could write something like this:

```{r}
for (i in 1:3){
  y = i + 2
  print(y/3)
}
```

Assigning variables in loops provides us the flexibility to carry out more complicated tasks and refer to the variables created in the loop later in our code.

## While Loops

While loops are another common type of loop in R that allow us to execute tasks so long as the statement we set is true. 

```{r}
i <- 1
while (i < 6) {
  print(i)
  i <- i + 1
}
```

## Repeat Loops
The final type of loop we will cover in this course is a repeat loop. In a repeat loop there is no condition check placed before the loop as in a while loop. Instead a condition check is placed within the loop and a break is utilized to escape the loop.

```{r}
x <- 100
repeat{
  x <- x *2
  print(x)
  if (x >= 1000)
  break
}
```

# Functions

## Refresh: What is a function?

Functions define a set of tasks we wish to apply in the same order each time the function is called. The greatest benefit of writing a function is that it can be applied beyond a single use. We use the following structure to create our own functions:

```{r}
#the_name_of_my_function <- function(thing applied to function){
#  things we want the function to do to the thing applied to the function
#}
```

This is a general schema for a function. We can execute simple commands with a function such as the one below:

```{r}
my_fun <- function(a_string){
  print(a_string)
}

my_fun(a_string = "Coding is fun!")
```

## Build a Function

To define a function in R, we use the following syntax:

``` {r}
# Define function to calculate mean (sd)
mean_SD <- function(x){
  myMean <- mean(x)
  mySD <- sd(x)
  paste0(round(myMean, digits = 2), ' (', round(mySD, digits = 2), ')')
}
mean_SD(x = randomData$Cont1)
  # Calculate individual values
  # ADD COD HERE

  # Combine values
  # ADD COD HERE

# ADD CODE HERE
```

When we run a function, no intermediate values are saved. The only output from the function will be the final value you return.

We can also provide default values for terms in a function.

``` {r}
# Define a function to calculate a mean or a median
contSummary <- function(x,normal = T) {
  
  # Calculate mean (sd) if normally distributed (the default)
  if (normal == T) {
      # Calculate individual values
    myMean <- round(mean(x),2)
    mySD <- round(sd(x),2)
    # Combine values
    paste0(myMean,' (',mySD,')')
  }
  # Calculate median (IQR) if non-normally distributed
  else {
    # Calculate individual values
    myMedian <- round(median(x))
    myIQR1 <- round(quantile(x,1/4),digits = 2)
    myIQR2 <- round(quantile(x,3/4),digits = 2)
    # Combine values
    paste0(myMedian,' [',myIQR1,', ',myIQR2,']')
  }
}

# Run function on normally distributed variable
contSummary(x = randomData$Cont1,normal = T)

# Run function on non-normally distributed variable
contSummary(x = randomData$Cont3,normal = F)
```

If we don't specify the "normal" term which we set a default for, the function will assume that it is normally distributed.

``` {r}
contSummary(x = randomData$Cont1)
contSummary(x = randomData$Cont3)
```

## The *apply* Function

First, let's generate a new data set with 20 different continuous, normally distributed variables.

``` {r}
set.seed(1234)

# Building empty data set
randomData2 <- as.data.frame(matrix(nrow = 100,ncol = 20))

# Generate 20 column names
colnames(randomData2) <- paste0('contVar',seq(1:ncol(randomData2)))

# Generate random means and SDs
means <- runif(20,min = 10,max = 30)
sds <- runif(20,min = 0.5,max = 5)

# Generate 20 normally distributed variables
for (i in 1:ncol(randomData2)) {
  randomData2[,i] <- rnorm(100,mean = means[i],sd = sds[i])
}

head(randomData2)
```

Say we wanted to look at the mean of each of these variables. We could loop through and calculate the mean iteratively for each variable like this:

``` {r}
# Generate am empty vector of means
meansCalc1 <- array(dim = ncol(randomData2))
names(meansCalc1) <- colnames(randomData2)

# Look at our empty vector
meansCalc1

# Loop through each column
for (i in colnames(randomData2)) {
  # Calculate the mean of values in that column
  meansCalc1[i] <- mean(randomData2[,i])
}

# Print final vector
meansCalc1

# Compare to the list of means we used to generate our data
cbind(means,meansCalc1)
```

This requires several lines of code and, as we start working with bigger data, can be computationally intensive. Luckily, we can also do this with a single line of code using the *apply()* function. For this function, you will provide 3 inputs:

1. The data frame (m x n) you want to use the apply function on. Note: The apply function will include every row and every column so ensure that you provide it with an appropriate subset of your data if necessary.
2. The "margin" i.e. if you want it to perform this function on rows or columns."**MARGIN = 1**" indicates it should perform the function on every row, resulting in an array of **m length** and "**MARGIN = 2**" indicates it should perform the function on every column, resulting in an array of **n length**.
3. The function you want it to apply on those rows or columns. You can either specify an existing function by name or define your own in line (more on this later).

So, we can recreate the same array of means we created in the loop above, now using a single line of code like this:

``` {r}
# Calculate the average of each column
# ADD CODE HERE

# Compare to our previous calculations
cbind(means,meansCalc1,meansCalc2)
table(meansCalc1 == meansCalc2)
```

You can see that changing the margin changes the dimensions of our output:

``` {r}
# Calculate the average of each row
# ADD CODE HERE

rowMeanCalc
```

We can also apply functions we have defined ourselves, like the function we defined above to summarize continuous variables. 

``` {r}
contSummary
```

Notice that the only input required for this function is a single array. Importantly, to use the apply function it can only take input as an array because you will only ever be inputting an array of rows or an array of columns. Now we can use the apply function to calculate summary statistics as follows:

``` {r}
# ADD CODE HERE
```

You can also define function in line, although for anything complex it is best practice to define it as a function up front. 

For example, if I am working with gene expression data, I might want to log2 normalize it prior to calculating my summary statistics.

```{r}
apply(randomData2,MARGIN = 2,FUN = function(x) {log2(mean(x))})
```

Or, if you want to define additional inputs for a function you can do it like this:

```{r}
apply(randomData2,MARGIN = 2,FUN = function(x) {contSummary(x,normal = F)})
```

# Leverage Loops and Functions to Analyze Data
Now that we have completed a quick review of loops and functions, we can use our new knowledge to read in several files at once and conduct some interesting analysis on our data. We have provided you with five files containing meta data information for 5 separate studies.

Let's list all of these files in our Data_Analytics_1_Lesson_Data directory in the /data directory on GitHub.

```{r}
#Please note that your path will likely be different! Make sure you point to where you downloaded this directory on your personal computer.

filenames <- list.files(path = "data_analytics_session1_data", pattern = ".csv")
print(filenames)
```

In the above code we are asking R to look in our specific directory for files with a .csv extension.

I'm curious, what exactly is in these metadata files we will be working with today? We can implement a for loop to take a look at the first 5 rows of each file.

```{r}
setwd("data_analytics_session1_data")

# ADD CODE HERE
```

It looks like in each file we have 6 columns including participant ID, age, sex, race, socioeconomic status (SES), and disease status. This is a lot of information for us to digest. It is often advantageous to take a look at the spread of our data using summary statistics in R. Let's do this now for the variable "age" in our five files.

```{r, warning = FALSE}
setwd("/Users/tobylanser/Documents/Dartmouth/qbs_bootcamp/qbsbootcampday3/data_analytics_session1_data")
filenames <- list.files(path = "data_analytics_session1_data", pattern = ".csv")
for (file in filenames){
  the_file <- read.csv(file)
  print(head(the_file))
}
```

"summary()" provides us with quite a bit of information for each file:

* Min. - the minimum of our data column
* 1st Qu. - the first quartile is the value under which 25% of data points are found when they are arranged in increasing order.
* Median - the median value of our data column
* 3rd Qu. - the third quartile is the value under which 75% of the data points are found when they are arranged in increasing order.
* Max - the maximum of our data columns

It's great to have information on our age data that we can put in a table, but we might find it useful to visualize our data with a figure. We can observe the distribution of the age information using a histogram. Let's generate a histogram for age in each of our five studies.

```{r}
# load libraries
library(ggplot2)

# set working directory
setwd("~/Ash's Documents/QBS PhD Program_2024/bootcamp_2025/data_analytics/data_analytics_session1_data")

for (file in filenames){
  the_file <- read.csv(file)
  # ADD CODE HERE
}
```

We can see from this histogram that the age variable for each of sample data sets follows a roughly normal distribution. We can also visualize more than one variable using a box plot. let's look at the distribution of age by sex.

```{r}
setwd("~/Ash's Documents/QBS PhD Program_2024/bootcamp_2025/data_analytics/data_analytics_session1_data")

for (file in filenames){
  the_file <- read.csv(file)
  age_var <- the_file$age
  # ADD CODE HERE
}
```

I personally would like to introduce all of you to the Harry Potter R color palette by creating bar plots for the distribution of age across the race category. Here I am implementing the "ronweasley" color scale. You can explore the use of this color palette [here](https://github.com/aljrico/harrypotter).

```{r}
# install package
#install.packages("harrypotter")
library(harrypotter)

# set working directory
setwd("~/Ash's Documents/QBS PhD Program_2024/bootcamp_2025/data_analytics/data_analytics_session1_data")

for (file in filenames){
  the_file <- read.csv(file)
  age_var <- the_file$age
  # ADD CODE HERE
}
```

We have learned some really useful analytic methods here! We can generate plots as well as summary statistics, but it is quite labor intensive to write this code over and over again for different projects that will require the same analysis. In order to circumvent this and save our future selves some time, we can generate a function that carries out all these tasks. Let's have our function take a single directory containing .csv files we wish to analyze. This function will generate summary statistics for each data set along with a histogram of the age and box plots for the distribution of age by race and disease status.

```{r, warning = FALSE}
# add comments to explain each part of code
fun_stats_pretty_plots <- function(path_to_directory){
  filenames <- list.files(path = path_to_directory, pattern = ".csv")
  for (file in filenames){
    the_file <- read.csv(file)
    age_var <- the_file$age
    print(summary(age_var))
    histogram <- ggplot(the_file, aes(x=age_var)) + geom_histogram(bins = 10, fill = "darkgreen")
    box_plot_race <- ggplot(the_file, aes(x=race, y=age, fill = race)) +
    geom_boxplot() + scale_fill_hp_d(option = "ronweasley")
    box_plot_disease_status <- ggplot(the_file, aes(x=disease_status, y=age, fill = disease_status)) +
    geom_boxplot() + scale_fill_hp_d(option = "lunalovegood")

    plot(histogram)
    plot(box_plot_race)
    plot(box_plot_disease_status)
  }
}

setwd("~/Ash's Documents/QBS PhD Program_2024/bootcamp_2025/data_analytics/data_analytics_session1_data")
fun_stats_pretty_plots("~/Ash's Documents/QBS PhD Program_2024/bootcamp_2025/data_analytics/data_analytics_session1_data")
```

This is great! We can apply this function to any other directory containing the same or similar .csv files. We might have to alter the function if we are hoping to look at other variables. Other experiments could have continuous variables you are interested in visualizing such as blood cell counts or concentrations of contaminants. The possibilities are endless!

# Create Table One

In the epidemiology and data science communities, a table summarizing the demographics of a study population is typically referred to as a "table one". Such a table might look like this.

```{r}
# install packages 
install.packages("tableone")
library(tableone)
```

```{r}
# load data
sample_data <- read.csv("~/Ash's Documents/QBS PhD Program_2024/bootcamp_2025/data_analytics/data_analytics_session1_data/sample_data_1.csv")

dim(sample_data)
colnames(sample_data)
#View(sample_data)
```

``` {r}
# create table one
# ADD CODE HERE

# display table one
print(table_one, showAllLevels = TRUE)
# option for nonnormal tests

# save table one as CSV
table_one_df <- as.data.frame(print(table_one, showAllLevels = TRUE, printToggle = FALSE))

write.csv(table_one_df, "~/Ash's Documents/QBS PhD Program_2024/bootcamp_2025/table_one_example.csv")
```

